{"data":{"featured":{"edges":[{"node":{"frontmatter":{"title":"IEEE VIP Cup  2021","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAECAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB7edoZZH/xAAYEAEBAQEBAAAAAAAAAAAAAAABAAIREP/aAAgBAQABBQK0pZV852L/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAbEAACAwADAAAAAAAAAAAAAAAAAREhMRBBUf/aAAgBAQABPyGzOmI3wUOV3w0oxao//9oADAMBAAIAAwAAABBz7//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABcRAQEBAQAAAAAAAAAAAAAAABEAQWH/2gAIAQIBAT8QHY7f/8QAHBABAAMAAgMAAAAAAAAAAAAAAQARITFBUWFx/9oACAEBAAE/EB63M5BNQl652OaGwFGjxK9w1VpKz7BFotuf/9k="},"images":{"fallback":{"src":"/static/d8176dcd7e730f30e6f3aea56b8b1b27/452ad/vip21.jpg","srcSet":"/static/d8176dcd7e730f30e6f3aea56b8b1b27/0ae72/vip21.jpg 175w,\n/static/d8176dcd7e730f30e6f3aea56b8b1b27/2aa80/vip21.jpg 350w,\n/static/d8176dcd7e730f30e6f3aea56b8b1b27/452ad/vip21.jpg 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/d8176dcd7e730f30e6f3aea56b8b1b27/ab668/vip21.avif 175w,\n/static/d8176dcd7e730f30e6f3aea56b8b1b27/058cc/vip21.avif 350w,\n/static/d8176dcd7e730f30e6f3aea56b8b1b27/dcbdb/vip21.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/d8176dcd7e730f30e6f3aea56b8b1b27/892e4/vip21.webp 175w,\n/static/d8176dcd7e730f30e6f3aea56b8b1b27/a4a82/vip21.webp 350w,\n/static/d8176dcd7e730f30e6f3aea56b8b1b27/4213d/vip21.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":474}}},"tech":["Augmentation","Semi-supervised","Heatmap","Pose"],"github":null,"external":"https://signalprocessingsociety.org/community-involvement/vip-cup-2021-icip-2021","position":"1st Position"},"html":"<ul>\n<li>\n<p align=\"left\">More than 50 teams from different universities around the world participated.</p>\n</li>\n<li>\n<p align=\"left\">We competed against <i>Hong Kong Polytechnic University</i> and <i>University in Moratuwa</i>, Sri Lanka teams in the final round.</p>\n</li>\n<li>\n<p align=\"left\">We built an In-bed Human Body Key-point and Pose detection System using Long Range InfraRed(LWIR) images at adverse lighting and covered conditions.</p>\n</li>\n<li>\n<p align=\"left\">Our <b>Team Samaritan</b> achieved 1st Position and was awarded with a prize money of $5000.</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Deep Learning  Sprint 2022","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAUCA//EABUBAQEAAAAAAAAAAAAAAAAAAAAC/9oADAMBAAIQAxAAAAHPK6mYyuP/xAAbEAABBAMAAAAAAAAAAAAAAAACAAEREgMTIf/aAAgBAQABBQLkQthKg1oEjjB2/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAEREv/aAAgBAwEBPwHKpf/EABYRAQEBAAAAAAAAAAAAAAAAAAARIf/aAAgBAgEBPwGNf//EABgQAAMBAQAAAAAAAAAAAAAAAAABMhBB/9oACAEBAAY/ApzhKJRKP//EAB4QAAICAAcAAAAAAAAAAAAAAAABESFBUWFxkbHB/9oACAEBAAE/IXZ6J4CQoUFsXugi0GRfeM//2gAMAwEAAgADAAAAEGMv/8QAGBEAAgMAAAAAAAAAAAAAAAAAAAERIWH/2gAIAQMBAT8QTTZof//EABgRAAMBAQAAAAAAAAAAAAAAAAABESFR/9oACAECAQE/EE90nR//xAAbEAEAAwEAAwAAAAAAAAAAAAABABEhQTFRYf/aAAgBAQABPxA4Pi+IJeMFuofpBgVjea7xGoDFXj1LgxFPGf/Z"},"images":{"fallback":{"src":"/static/5d1b82934962d424c21eadf6a4277b39/9bd6b/dlsprint.jpg","srcSet":"/static/5d1b82934962d424c21eadf6a4277b39/81770/dlsprint.jpg 175w,\n/static/5d1b82934962d424c21eadf6a4277b39/0b3a5/dlsprint.jpg 350w,\n/static/5d1b82934962d424c21eadf6a4277b39/9bd6b/dlsprint.jpg 700w,\n/static/5d1b82934962d424c21eadf6a4277b39/a1503/dlsprint.jpg 1400w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/5d1b82934962d424c21eadf6a4277b39/96e31/dlsprint.avif 175w,\n/static/5d1b82934962d424c21eadf6a4277b39/c7b75/dlsprint.avif 350w,\n/static/5d1b82934962d424c21eadf6a4277b39/66766/dlsprint.avif 700w,\n/static/5d1b82934962d424c21eadf6a4277b39/f8eb3/dlsprint.avif 1400w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/5d1b82934962d424c21eadf6a4277b39/37045/dlsprint.webp 175w,\n/static/5d1b82934962d424c21eadf6a4277b39/589aa/dlsprint.webp 350w,\n/static/5d1b82934962d424c21eadf6a4277b39/b76e8/dlsprint.webp 700w,\n/static/5d1b82934962d424c21eadf6a4277b39/48a80/dlsprint.webp 1400w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":369}}},"tech":["Speech-2-text","Wav2Vec2","Augmentation","Nemo"],"github":null,"external":"https://www.kaggle.com/competitions/dlsprint/discussion/349991","position":"2nd Position"},"html":"<ul>\n<li>\n<p align=\"left\">59 teams from all over Bangladesh as well as overseas participated through Kaggle.</p>\n</li>\n<li>\n<p align=\"left\">We built a <b>Wav2Vec2.0 based Bangla text‑to‑speech language model</b>, that can correctly transcript Bangla Speech.</p>\n</li>\n<li>\n<p align=\"left\">Our <b>Team Ekush</b> achieved the 2nd Position and was awarded with a prize money of 60000 Taka.</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"IEEE VIP Cup 2022","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACvklEQVQ4y32SS0hUYRiGZ5W1sBZRSUkFrYoI2rSqFkVKFLXoZnah1BIrojA9iqeZGg0zdbK0MkzNinDKSs2yi2S7oBBMSjMjEkTneuZyzpyZcebME3M0IyR/eHj5X/7v5fs+fkNSxjUWZVWSfMJCSmkTKWWNpFY0kFp5h1TLbTaUV7OpqoYt1TVsvVXDxupyNtdWknrHQkr9FTbVl7Ks8jQLy4+TZDmGISGtlIQDJcw+bCYxy8zc7Ask5hhZnGsmWbjI4gIjyeJ5lppElpuLWGLOI7kkl3mmHOaX5DC3OJM5JYeZdSmdhMtpGMTmbkTrO8RHXRQ9foNg7STf2kFhSwcFLe0IT1oRnrUitD1FaGuh4PljCjqsCC+tCJ3NFHVZEd9ZEbubEd8/xMC0o+nEIlGIRie9GEQ00OI66YTCaMHgtGpDVNOIE9E0vfD1h0HauvsYHRnmc18frS/e8urTF7q+9fLj+1f6B3t4//E1I04JXwjGIxGisYmMOIZYLEYc4gDZF5rYflRELKsl89Q5Vq5ey4J0I2vqTFzPO07ekRQ27F9BrnEXdxuvIAfkiY4ncwx/LvHuohr09A3QcN9KZsZJhEITdTctrNq8k/UZaVytMLJv9zb27lzFoYPreHCvAsnj5m8GfwP/GDdqy8k4kU771WLyTuVwZM8Ozp3MJv/MWZrbH1J1rYImUxpCfjo1dVUoin/mwJ+/Bugf7MU+Nsav4WGGhn7ou4nvymYbQfb7kLwBvF4Xst89tappgZMuSjiET1UJhsKEx8d1fH4ZWQmgBkMoqooSCBBQg6jB8FTtfzuUPB7GbHZGbTbG7HZsdgd2h5NRm11Xm8OhE39jdzrR9N8xQ6DH68XhdOF0uXVckvSPOt1u3JKEw+XC7fHMFDgxtdfnx+WW9LFkRdFHnVAFWVbwy8rUPaCq00b+DebjXgSEpjr5AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/dc572c331f33b940975b4d1d54f508f7/14d3a/vip22.png","srcSet":"/static/dc572c331f33b940975b4d1d54f508f7/eaf0a/vip22.png 175w,\n/static/dc572c331f33b940975b4d1d54f508f7/4f2d3/vip22.png 350w,\n/static/dc572c331f33b940975b4d1d54f508f7/14d3a/vip22.png 700w,\n/static/dc572c331f33b940975b4d1d54f508f7/42391/vip22.png 1400w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/dc572c331f33b940975b4d1d54f508f7/66dfe/vip22.avif 175w,\n/static/dc572c331f33b940975b4d1d54f508f7/2414d/vip22.avif 350w,\n/static/dc572c331f33b940975b4d1d54f508f7/f9f2e/vip22.avif 700w,\n/static/dc572c331f33b940975b4d1d54f508f7/eeb66/vip22.avif 1400w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/dc572c331f33b940975b4d1d54f508f7/08151/vip22.webp 175w,\n/static/dc572c331f33b940975b4d1d54f508f7/cf1dd/vip22.webp 350w,\n/static/dc572c331f33b940975b4d1d54f508f7/ad713/vip22.webp 700w,\n/static/dc572c331f33b940975b4d1d54f508f7/4d375/vip22.webp 1400w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":471.00000000000006}}},"tech":["Pytorch","GANs","Synthetic","Detection"],"github":null,"external":"https://2022.ieeeicip.org/video-and-image-processing-cup/","position":"3rd Position"},"html":"<ul>\n<li>\n<p align=\"left\"> More than 60 teams from different universities around  the world participated, top three teams competed in the final round at <i>ICIP 2022</i>.</p>\n</li>\n<li>\n<p align=\"left\">We built a <i>generalized detector for identifying real, synthetic and partially manipulated image</i> by GANs as well as Diffusion models.</p>\n</li>\n<li>\n<p align=\"left\">Our <b>Team Sherlock</b> <i>co-mentoredby me</i> achieved 3rd Position and was awarded with a prize money of $1500.</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Robi Datathon 2.0","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEDAv/EABYBAQEBAAAAAAAAAAAAAAAAAAAEBf/aAAwDAQACEAMQAAABhqbn1kAf/8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEREiD/2gAIAQEAAQUCQ4rj/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRAAAgMBAAAAAAAAAAAAAAAAARAAESFR/9oACAEBAAE/IaA6LnFqD//aAAwDAQACAAMAAAAQ6C//xAAWEQEBAQAAAAAAAAAAAAAAAAARECH/2gAIAQMBAT8QHZ//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhQRAxUf/aAAgBAQABPxB3GFa9mACL4XZu4kTFXvj/2Q=="},"images":{"fallback":{"src":"/static/91599747a540a2683a35f75e26bd1955/bddbf/datathon2.jpg","srcSet":"/static/91599747a540a2683a35f75e26bd1955/20376/datathon2.jpg 175w,\n/static/91599747a540a2683a35f75e26bd1955/05972/datathon2.jpg 350w,\n/static/91599747a540a2683a35f75e26bd1955/bddbf/datathon2.jpg 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/91599747a540a2683a35f75e26bd1955/dee2e/datathon2.avif 175w,\n/static/91599747a540a2683a35f75e26bd1955/9c5ce/datathon2.avif 350w,\n/static/91599747a540a2683a35f75e26bd1955/7b88a/datathon2.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/91599747a540a2683a35f75e26bd1955/a2e69/datathon2.webp 175w,\n/static/91599747a540a2683a35f75e26bd1955/14999/datathon2.webp 350w,\n/static/91599747a540a2683a35f75e26bd1955/b9339/datathon2.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":404}}},"tech":["Big-data","Time-series","Visualization","Analysis"],"github":null,"external":"https://www.robi.com.bd/en/datathon","position":"Top 10"},"html":"<ul>\n<li>\n<p align=\"left\">The Datathon competition was organized by the country’s leading digital operator Robi. </p>\n</li>\n<li>\n<p align=\"left\"> Datathon 2.0 was powered by ‘AWS’ (Amazon Web Services), ‘Huawei’ was the platinum sponsor, and ‘Brain station’ was the cloud expertise partner, reads a press release.</p>\n</li>\n<li>\n<p align=\"left\">More than 2,800 participants from 11 countries took part in the Datathon 2.0 competition. </p>\n</li>\n<li>\n<p align=\"left\">Following a tough competition, 100 participants took part in the final round grouped into 25 teams.</p>\n</li>\n<li>\n<p align=\"left\">From those 25 teams, top 10 Teams were selected for further Presntation and Analysis.</p>\n</li>\n</ul>"}}]}}}